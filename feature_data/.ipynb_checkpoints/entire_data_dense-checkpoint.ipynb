{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "651c1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "98f5c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_json('dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d53c3be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_dir</th>\n",
       "      <th>img_dir</th>\n",
       "      <th>slice_file_name</th>\n",
       "      <th>fold</th>\n",
       "      <th>salience</th>\n",
       "      <th>classID</th>\n",
       "      <th>class</th>\n",
       "      <th>chroma_stft</th>\n",
       "      <th>spec_cent</th>\n",
       "      <th>spec_bw</th>\n",
       "      <th>rolloff</th>\n",
       "      <th>zcr</th>\n",
       "      <th>mfcc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>100032-3-0-0.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>dog_bark</td>\n",
       "      <td>[[1.0, 0.9962427616, 0.0190000143, 0.026201011...</td>\n",
       "      <td>[[2883.7319579556, 1918.4464091835, 1753.42278...</td>\n",
       "      <td>[[4137.6484742892, 2649.4459236982, 2077.54802...</td>\n",
       "      <td>[[3402.24609375, 2627.05078125, 2497.8515625, ...</td>\n",
       "      <td>[[0.029785156200000003, 0.0390625, 0.050292968...</td>\n",
       "      <td>[[-454.3000488281, -378.7392578125, -278.98052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>100263-2-0-117.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>[[0.3719767034, 0.47527202960000003, 0.5731680...</td>\n",
       "      <td>[[2846.4354925768, 2523.356998236, 2104.251644...</td>\n",
       "      <td>[[3250.6217185607, 3075.3911828068, 3011.01217...</td>\n",
       "      <td>[[5727.83203125, 5124.90234375, 4565.0390625, ...</td>\n",
       "      <td>[[0.03125, 0.0400390625, 0.052246093800000004,...</td>\n",
       "      <td>[[-528.8467407227, -517.7744140625, -515.84240...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>100263-2-0-121.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>[[0.5370306373, 0.7598083615, 0.4346997738, 0....</td>\n",
       "      <td>[[2025.6195967712, 1912.6816671099, 1863.82073...</td>\n",
       "      <td>[[2478.9122233193, 2317.4434579393, 2257.51215...</td>\n",
       "      <td>[[3703.7109375, 3660.64453125, 3617.578125, 38...</td>\n",
       "      <td>[[0.014160156200000001, 0.0258789062, 0.032226...</td>\n",
       "      <td>[[-551.6820678711, -537.4987182617, -542.29864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>100263-2-0-126.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>[[1.0, 1.0, 0.7334994674, 0.47476378080000003,...</td>\n",
       "      <td>[[2423.591361566, 2592.2168736279, 2668.131064...</td>\n",
       "      <td>[[2528.1100213423, 2636.6084439854, 2632.93598...</td>\n",
       "      <td>[[4134.375, 4306.640625, 4457.373046875, 4457....</td>\n",
       "      <td>[[0.0341796875, 0.05859375, 0.0849609375, 0.09...</td>\n",
       "      <td>[[-485.5311584473, -481.130859375, -478.738372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>/Users/lizzy/Desktop/Universita/cesab/project/...</td>\n",
       "      <td>100263-2-0-137.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>[[0.4104263783, 0.5540543199, 0.87226367, 0.99...</td>\n",
       "      <td>[[2095.7059081013, 1977.3218872164, 1821.78414...</td>\n",
       "      <td>[[2483.5988276219, 2361.137258414, 2297.652143...</td>\n",
       "      <td>[[4026.708984375, 4005.17578125, 3919.04296875...</td>\n",
       "      <td>[[0.0170898438, 0.034667968800000004, 0.046386...</td>\n",
       "      <td>[[-518.1114501953, -510.7933959961, -511.39547...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            file_dir  \\\n",
       "0  /Users/lizzy/Desktop/Universita/cesab/project/...   \n",
       "1  /Users/lizzy/Desktop/Universita/cesab/project/...   \n",
       "2  /Users/lizzy/Desktop/Universita/cesab/project/...   \n",
       "3  /Users/lizzy/Desktop/Universita/cesab/project/...   \n",
       "4  /Users/lizzy/Desktop/Universita/cesab/project/...   \n",
       "\n",
       "                                             img_dir     slice_file_name  \\\n",
       "0  /Users/lizzy/Desktop/Universita/cesab/project/...    100032-3-0-0.wav   \n",
       "1  /Users/lizzy/Desktop/Universita/cesab/project/...  100263-2-0-117.wav   \n",
       "2  /Users/lizzy/Desktop/Universita/cesab/project/...  100263-2-0-121.wav   \n",
       "3  /Users/lizzy/Desktop/Universita/cesab/project/...  100263-2-0-126.wav   \n",
       "4  /Users/lizzy/Desktop/Universita/cesab/project/...  100263-2-0-137.wav   \n",
       "\n",
       "   fold  salience  classID             class  \\\n",
       "0     5         1        3          dog_bark   \n",
       "1     5         1        2  children_playing   \n",
       "2     5         1        2  children_playing   \n",
       "3     5         1        2  children_playing   \n",
       "4     5         1        2  children_playing   \n",
       "\n",
       "                                         chroma_stft  \\\n",
       "0  [[1.0, 0.9962427616, 0.0190000143, 0.026201011...   \n",
       "1  [[0.3719767034, 0.47527202960000003, 0.5731680...   \n",
       "2  [[0.5370306373, 0.7598083615, 0.4346997738, 0....   \n",
       "3  [[1.0, 1.0, 0.7334994674, 0.47476378080000003,...   \n",
       "4  [[0.4104263783, 0.5540543199, 0.87226367, 0.99...   \n",
       "\n",
       "                                           spec_cent  \\\n",
       "0  [[2883.7319579556, 1918.4464091835, 1753.42278...   \n",
       "1  [[2846.4354925768, 2523.356998236, 2104.251644...   \n",
       "2  [[2025.6195967712, 1912.6816671099, 1863.82073...   \n",
       "3  [[2423.591361566, 2592.2168736279, 2668.131064...   \n",
       "4  [[2095.7059081013, 1977.3218872164, 1821.78414...   \n",
       "\n",
       "                                             spec_bw  \\\n",
       "0  [[4137.6484742892, 2649.4459236982, 2077.54802...   \n",
       "1  [[3250.6217185607, 3075.3911828068, 3011.01217...   \n",
       "2  [[2478.9122233193, 2317.4434579393, 2257.51215...   \n",
       "3  [[2528.1100213423, 2636.6084439854, 2632.93598...   \n",
       "4  [[2483.5988276219, 2361.137258414, 2297.652143...   \n",
       "\n",
       "                                             rolloff  \\\n",
       "0  [[3402.24609375, 2627.05078125, 2497.8515625, ...   \n",
       "1  [[5727.83203125, 5124.90234375, 4565.0390625, ...   \n",
       "2  [[3703.7109375, 3660.64453125, 3617.578125, 38...   \n",
       "3  [[4134.375, 4306.640625, 4457.373046875, 4457....   \n",
       "4  [[4026.708984375, 4005.17578125, 3919.04296875...   \n",
       "\n",
       "                                                 zcr  \\\n",
       "0  [[0.029785156200000003, 0.0390625, 0.050292968...   \n",
       "1  [[0.03125, 0.0400390625, 0.052246093800000004,...   \n",
       "2  [[0.014160156200000001, 0.0258789062, 0.032226...   \n",
       "3  [[0.0341796875, 0.05859375, 0.0849609375, 0.09...   \n",
       "4  [[0.0170898438, 0.034667968800000004, 0.046386...   \n",
       "\n",
       "                                                mfcc  \n",
       "0  [[-454.3000488281, -378.7392578125, -278.98052...  \n",
       "1  [[-528.8467407227, -517.7744140625, -515.84240...  \n",
       "2  [[-551.6820678711, -537.4987182617, -542.29864...  \n",
       "3  [[-485.5311584473, -481.130859375, -478.738372...  \n",
       "4  [[-518.1114501953, -510.7933959961, -511.39547...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "03509656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data splitting\n",
    "data = dataset.drop([\"file_dir\", \"slice_file_name\", \"img_dir\", \"classID\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1941144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(row):\n",
    "    if(np.array(row['spec_cent'][0]).shape[0]) == 345:\n",
    "        s = np.array([row[\"salience\"]] * np.array(row['spec_cent'][0]).shape[0])\n",
    "        matr = [np.array(row[\"spec_cent\"][0]),\n",
    "                np.array(row[\"spec_bw\"][0]), \n",
    "                np.array(row[\"rolloff\"][0]), \n",
    "                np.array(row[\"zcr\"][0]),\n",
    "                s]\n",
    "        for i in range(20):\n",
    "            matr.append(np.array(row[\"mfcc\"][i]))\n",
    "        for i in range(12):\n",
    "            matr.append(np.array(row[\"chroma_stft\"][i]))\n",
    "        return np.array(matr)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4710bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[(data[\"fold\"] == 1) | (data[\"fold\"] == 2) | (data[\"fold\"] == 3) | (data[\"fold\"] == 4) | (data[\"fold\"] == 6)]\n",
    "test = data[(data[\"fold\"] == 5) | (data[\"fold\"] == 7) | (data[\"fold\"] == 8) | (data[\"fold\"] == 9) | (data[\"fold\"] == 10)]\n",
    "\n",
    "X_train = train.reset_index()\n",
    "\n",
    "X_test = test.drop([\"class\", \"fold\"], axis = 1)\n",
    "y_test = test[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c30c0b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m = np.ndarray(shape=(3792, 37, 345))\n",
    "j = 0\n",
    "to_drop = []\n",
    "for index, row in train.iterrows():\n",
    "    r = to_matrix(row)\n",
    "    if not np.any(np.isnan(r)):\n",
    "        X_train_m[j] = r\n",
    "        j = j + 1\n",
    "    else:\n",
    "        to_drop.append([index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a50a4576",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = np.setdiff1d(train.index, to_drop)\n",
    "X_train = data.loc[to_keep]\n",
    "X_train = X_train.reset_index()\n",
    "X_train_fold = X_train[\"fold\"]\n",
    "X_train_indices = X_train.index\n",
    "y_train = X_train[\"class\"]\n",
    "y_train_indices = y_train.index\n",
    "X_train = X_train_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "428ff826",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.ndarray(shape=(3534, 37, 345))\n",
    "j = 0\n",
    "for index, row in test.iterrows():\n",
    "    r = to_matrix(row)\n",
    "    if not np.any(np.isnan(r)):\n",
    "        X_test[j] = r\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4ff28426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "992b6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
    "\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b0887af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0f4c98d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folds = [4]\n",
    "validation_dict = {}\n",
    "for fold in training_folds:\n",
    "    #preparing validation folds\n",
    "    X_val = X_train[(X_train_fold == fold) | (X_train_fold == fold)]\n",
    "    X_val_indices = X_train_indices[(X_train_fold == fold) | (X_train_fold == fold)]\n",
    "    y_val = y_train[(X_train_fold == fold) | (X_train_fold == fold)]\n",
    "    y_val_indices = y_train_indices[(X_train_fold == fold) | (X_train_fold == fold)]\n",
    "    X = X_train[np.isin(X_train_indices,np.setdiff1d(X_train_indices, X_val_indices))]\n",
    "    y = y_train[np.isin(y_train_indices,np.setdiff1d(y_train_indices, y_val_indices))]\n",
    "    validation_dict[fold] = {'X' : X, 'y' : y, 'X_val': X_val, 'y_val': y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b338ecd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_128 (Dense)            (None, 345)               4404270   \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 154)               53284     \n",
      "_________________________________________________________________\n",
      "dense_130 (Dense)            (None, 37)                5735      \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 154)               5852      \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 10)                1550      \n",
      "=================================================================\n",
      "Total params: 4,470,691\n",
      "Trainable params: 4,470,691\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2ef4a91f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2ef4a91f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "14/15 [===========================>..] - ETA: 0s - loss: 2.3653 - accuracy: 0.1025WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2ac9ae940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2ac9ae940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 2.3639 - accuracy: 0.1038 - val_loss: 2.3395 - val_accuracy: 0.1036\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 2.3188 - accuracy: 0.1275 - val_loss: 2.3081 - val_accuracy: 0.1282\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.2778 - accuracy: 0.1657 - val_loss: 2.2770 - val_accuracy: 0.1492\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.2471 - accuracy: 0.1936 - val_loss: 2.2483 - val_accuracy: 0.1689\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 2.2022 - accuracy: 0.2345 - val_loss: 2.2212 - val_accuracy: 0.2035\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.1776 - accuracy: 0.2501 - val_loss: 2.1949 - val_accuracy: 0.2182\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 2.1286 - accuracy: 0.3014 - val_loss: 2.1692 - val_accuracy: 0.2392\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 2.1053 - accuracy: 0.3236 - val_loss: 2.1440 - val_accuracy: 0.2565\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 2.0660 - accuracy: 0.3481 - val_loss: 2.1183 - val_accuracy: 0.2811\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 2.0338 - accuracy: 0.3813 - val_loss: 2.0923 - val_accuracy: 0.3009\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 1s 35ms/step - loss: 1.9929 - accuracy: 0.4131 - val_loss: 2.0650 - val_accuracy: 0.3169\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 1.9707 - accuracy: 0.4184 - val_loss: 2.0380 - val_accuracy: 0.3453\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 1.9353 - accuracy: 0.4486 - val_loss: 2.0101 - val_accuracy: 0.3736\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.8944 - accuracy: 0.4700 - val_loss: 1.9824 - val_accuracy: 0.3798\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.8718 - accuracy: 0.4745 - val_loss: 1.9541 - val_accuracy: 0.3835\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.8274 - accuracy: 0.5005 - val_loss: 1.9251 - val_accuracy: 0.4057\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 1.8020 - accuracy: 0.4994 - val_loss: 1.8978 - val_accuracy: 0.4168\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.7534 - accuracy: 0.5412 - val_loss: 1.8691 - val_accuracy: 0.4242\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.7234 - accuracy: 0.5554 - val_loss: 1.8410 - val_accuracy: 0.4316\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.6836 - accuracy: 0.5655 - val_loss: 1.8138 - val_accuracy: 0.4390\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.6616 - accuracy: 0.5683 - val_loss: 1.7869 - val_accuracy: 0.4525\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.6279 - accuracy: 0.5752 - val_loss: 1.7613 - val_accuracy: 0.4562\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.5847 - accuracy: 0.6047 - val_loss: 1.7362 - val_accuracy: 0.4587\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 1.5735 - accuracy: 0.5868 - val_loss: 1.7127 - val_accuracy: 0.4612\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.5221 - accuracy: 0.6127 - val_loss: 1.6896 - val_accuracy: 0.4661\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 1.4904 - accuracy: 0.6243 - val_loss: 1.6676 - val_accuracy: 0.4698\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.4548 - accuracy: 0.6466 - val_loss: 1.6466 - val_accuracy: 0.4698\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.4377 - accuracy: 0.6316 - val_loss: 1.6263 - val_accuracy: 0.4784\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.4157 - accuracy: 0.6398 - val_loss: 1.6068 - val_accuracy: 0.4797\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.3782 - accuracy: 0.6592 - val_loss: 1.5880 - val_accuracy: 0.4858\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 1.3427 - accuracy: 0.6587 - val_loss: 1.5700 - val_accuracy: 0.4895\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.3184 - accuracy: 0.6749 - val_loss: 1.5541 - val_accuracy: 0.4908\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.3035 - accuracy: 0.6706 - val_loss: 1.5377 - val_accuracy: 0.4932\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.2849 - accuracy: 0.6691 - val_loss: 1.5219 - val_accuracy: 0.4945\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 1.2366 - accuracy: 0.6939 - val_loss: 1.5081 - val_accuracy: 0.4994\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.2139 - accuracy: 0.6930 - val_loss: 1.4937 - val_accuracy: 0.4982\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.1748 - accuracy: 0.7101 - val_loss: 1.4802 - val_accuracy: 0.5006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.1871 - accuracy: 0.6930 - val_loss: 1.4675 - val_accuracy: 0.4994\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.1505 - accuracy: 0.7088 - val_loss: 1.4555 - val_accuracy: 0.4994\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 1.1095 - accuracy: 0.7322 - val_loss: 1.4448 - val_accuracy: 0.5031\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.1195 - accuracy: 0.7156 - val_loss: 1.4335 - val_accuracy: 0.4994\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0820 - accuracy: 0.7205 - val_loss: 1.4228 - val_accuracy: 0.5043\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.0542 - accuracy: 0.7320 - val_loss: 1.4127 - val_accuracy: 0.5031\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0757 - accuracy: 0.7137 - val_loss: 1.4040 - val_accuracy: 0.5080\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 1.0381 - accuracy: 0.7283 - val_loss: 1.3958 - val_accuracy: 0.5055\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 1.0200 - accuracy: 0.7377 - val_loss: 1.3870 - val_accuracy: 0.5068\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.9918 - accuracy: 0.7390 - val_loss: 1.3785 - val_accuracy: 0.5105\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.9863 - accuracy: 0.7414 - val_loss: 1.3712 - val_accuracy: 0.5117\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.9605 - accuracy: 0.7533 - val_loss: 1.3649 - val_accuracy: 0.5117\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.9484 - accuracy: 0.7516 - val_loss: 1.3566 - val_accuracy: 0.5154\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.9427 - accuracy: 0.7522 - val_loss: 1.3490 - val_accuracy: 0.5166\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.9352 - accuracy: 0.7572 - val_loss: 1.3444 - val_accuracy: 0.5166\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.9072 - accuracy: 0.7650 - val_loss: 1.3385 - val_accuracy: 0.5179\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.8667 - accuracy: 0.7821 - val_loss: 1.3329 - val_accuracy: 0.5191\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.8753 - accuracy: 0.7775 - val_loss: 1.3274 - val_accuracy: 0.5216\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.8522 - accuracy: 0.7760 - val_loss: 1.3218 - val_accuracy: 0.5216\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.8415 - accuracy: 0.7849 - val_loss: 1.3179 - val_accuracy: 0.5240\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.8224 - accuracy: 0.7891 - val_loss: 1.3132 - val_accuracy: 0.5240\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.8217 - accuracy: 0.7946 - val_loss: 1.3090 - val_accuracy: 0.5277\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.7852 - accuracy: 0.7974 - val_loss: 1.3059 - val_accuracy: 0.5277\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.7735 - accuracy: 0.8080 - val_loss: 1.3008 - val_accuracy: 0.5302\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.7906 - accuracy: 0.7927 - val_loss: 1.2973 - val_accuracy: 0.5314\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.7558 - accuracy: 0.8052 - val_loss: 1.2938 - val_accuracy: 0.5314\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.7621 - accuracy: 0.8015 - val_loss: 1.2909 - val_accuracy: 0.5339\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.7496 - accuracy: 0.8086 - val_loss: 1.2870 - val_accuracy: 0.5339\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.7378 - accuracy: 0.8162 - val_loss: 1.2850 - val_accuracy: 0.5339\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.7157 - accuracy: 0.8229 - val_loss: 1.2843 - val_accuracy: 0.5314\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.7103 - accuracy: 0.8210 - val_loss: 1.2795 - val_accuracy: 0.5388\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6915 - accuracy: 0.8304 - val_loss: 1.2775 - val_accuracy: 0.5388\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6979 - accuracy: 0.8210 - val_loss: 1.2759 - val_accuracy: 0.5413\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6704 - accuracy: 0.8307 - val_loss: 1.2724 - val_accuracy: 0.5401\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6652 - accuracy: 0.8301 - val_loss: 1.2704 - val_accuracy: 0.5413\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6465 - accuracy: 0.8371 - val_loss: 1.2688 - val_accuracy: 0.5450\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6405 - accuracy: 0.8389 - val_loss: 1.2695 - val_accuracy: 0.5425\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6349 - accuracy: 0.8470 - val_loss: 1.2673 - val_accuracy: 0.5450\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6301 - accuracy: 0.8418 - val_loss: 1.2654 - val_accuracy: 0.5438\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.6109 - accuracy: 0.8504 - val_loss: 1.2631 - val_accuracy: 0.5487\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6196 - accuracy: 0.8482 - val_loss: 1.2639 - val_accuracy: 0.5450\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5910 - accuracy: 0.8585 - val_loss: 1.2625 - val_accuracy: 0.5475\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.6137 - accuracy: 0.8417 - val_loss: 1.2623 - val_accuracy: 0.5487\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5781 - accuracy: 0.8591 - val_loss: 1.2607 - val_accuracy: 0.5450\n",
      "Epoch 82/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5746 - accuracy: 0.8525 - val_loss: 1.2596 - val_accuracy: 0.5499\n",
      "Epoch 83/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.5774 - accuracy: 0.8510 - val_loss: 1.2609 - val_accuracy: 0.5512\n",
      "Epoch 84/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.5528 - accuracy: 0.8611 - val_loss: 1.2602 - val_accuracy: 0.5524\n",
      "Epoch 85/200\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5431 - accuracy: 0.8669 - val_loss: 1.2605 - val_accuracy: 0.5524\n",
      "Epoch 86/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5700 - accuracy: 0.8565 - val_loss: 1.2596 - val_accuracy: 0.5524\n",
      "Epoch 87/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5560 - accuracy: 0.8616 - val_loss: 1.2598 - val_accuracy: 0.5512\n",
      "Epoch 88/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.5343 - accuracy: 0.8678 - val_loss: 1.2589 - val_accuracy: 0.5536\n",
      "Epoch 89/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.5455 - accuracy: 0.8597 - val_loss: 1.2598 - val_accuracy: 0.5524\n",
      "Epoch 90/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.5332 - accuracy: 0.8633 - val_loss: 1.2596 - val_accuracy: 0.5536\n",
      "Epoch 91/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5094 - accuracy: 0.8686 - val_loss: 1.2621 - val_accuracy: 0.5524\n",
      "Epoch 92/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.5167 - accuracy: 0.8742 - val_loss: 1.2621 - val_accuracy: 0.5536\n",
      "Epoch 93/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.5010 - accuracy: 0.8777 - val_loss: 1.2614 - val_accuracy: 0.5561\n",
      "Epoch 94/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.4859 - accuracy: 0.8836 - val_loss: 1.2625 - val_accuracy: 0.5598\n",
      "Epoch 95/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.4903 - accuracy: 0.8809 - val_loss: 1.2622 - val_accuracy: 0.5586\n",
      "Epoch 96/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.4947 - accuracy: 0.8822 - val_loss: 1.2626 - val_accuracy: 0.5598\n",
      "Epoch 97/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.4810 - accuracy: 0.8835 - val_loss: 1.2636 - val_accuracy: 0.5598\n",
      "Epoch 98/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4524 - accuracy: 0.8970 - val_loss: 1.2660 - val_accuracy: 0.5586\n",
      "Epoch 99/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4704 - accuracy: 0.8866 - val_loss: 1.2667 - val_accuracy: 0.5598\n",
      "Epoch 100/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4504 - accuracy: 0.8835 - val_loss: 1.2666 - val_accuracy: 0.5598\n",
      "Epoch 101/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4382 - accuracy: 0.8974 - val_loss: 1.2690 - val_accuracy: 0.5598\n",
      "Epoch 102/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4414 - accuracy: 0.8923 - val_loss: 1.2700 - val_accuracy: 0.5598\n",
      "Epoch 103/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4248 - accuracy: 0.8989 - val_loss: 1.2703 - val_accuracy: 0.5598\n",
      "Epoch 104/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4289 - accuracy: 0.8975 - val_loss: 1.2722 - val_accuracy: 0.5598\n",
      "Epoch 105/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4472 - accuracy: 0.8867 - val_loss: 1.2730 - val_accuracy: 0.5610\n",
      "Epoch 106/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4079 - accuracy: 0.9081 - val_loss: 1.2740 - val_accuracy: 0.5610\n",
      "Epoch 107/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4161 - accuracy: 0.9069 - val_loss: 1.2756 - val_accuracy: 0.5586\n",
      "Epoch 108/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.4017 - accuracy: 0.9009 - val_loss: 1.2764 - val_accuracy: 0.5586\n",
      "Epoch 109/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.4066 - accuracy: 0.9043 - val_loss: 1.2780 - val_accuracy: 0.5586\n",
      "Epoch 110/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3939 - accuracy: 0.9055 - val_loss: 1.2786 - val_accuracy: 0.5586\n",
      "Epoch 111/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.4121 - accuracy: 0.8957 - val_loss: 1.2810 - val_accuracy: 0.5573\n",
      "Epoch 112/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.3799 - accuracy: 0.9154 - val_loss: 1.2815 - val_accuracy: 0.5573\n",
      "Epoch 113/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3725 - accuracy: 0.9152 - val_loss: 1.2826 - val_accuracy: 0.5598\n",
      "Epoch 114/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3737 - accuracy: 0.9132 - val_loss: 1.2857 - val_accuracy: 0.5586\n",
      "Epoch 115/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3662 - accuracy: 0.9155 - val_loss: 1.2862 - val_accuracy: 0.5586\n",
      "Epoch 116/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3690 - accuracy: 0.9158 - val_loss: 1.2872 - val_accuracy: 0.5586\n",
      "Epoch 117/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3777 - accuracy: 0.9142 - val_loss: 1.2891 - val_accuracy: 0.5573\n",
      "Epoch 118/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3667 - accuracy: 0.9194 - val_loss: 1.2913 - val_accuracy: 0.5573\n",
      "Epoch 119/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3551 - accuracy: 0.9230 - val_loss: 1.2920 - val_accuracy: 0.5561\n",
      "Epoch 120/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3537 - accuracy: 0.9228 - val_loss: 1.2938 - val_accuracy: 0.5561\n",
      "Epoch 121/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3394 - accuracy: 0.9253 - val_loss: 1.2962 - val_accuracy: 0.5561\n",
      "Epoch 122/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3349 - accuracy: 0.9299 - val_loss: 1.2960 - val_accuracy: 0.5573\n",
      "Epoch 123/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3250 - accuracy: 0.9340 - val_loss: 1.2981 - val_accuracy: 0.5561\n",
      "Epoch 124/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3382 - accuracy: 0.9329 - val_loss: 1.3003 - val_accuracy: 0.5573\n",
      "Epoch 125/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3224 - accuracy: 0.9379 - val_loss: 1.3020 - val_accuracy: 0.5561\n",
      "Epoch 126/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3209 - accuracy: 0.9391 - val_loss: 1.3045 - val_accuracy: 0.5549\n",
      "Epoch 127/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3348 - accuracy: 0.9298 - val_loss: 1.3049 - val_accuracy: 0.5573\n",
      "Epoch 128/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3042 - accuracy: 0.9441 - val_loss: 1.3060 - val_accuracy: 0.5573\n",
      "Epoch 129/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3174 - accuracy: 0.9397 - val_loss: 1.3092 - val_accuracy: 0.5561\n",
      "Epoch 130/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3207 - accuracy: 0.9359 - val_loss: 1.3102 - val_accuracy: 0.5573\n",
      "Epoch 131/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3053 - accuracy: 0.9438 - val_loss: 1.3120 - val_accuracy: 0.5561\n",
      "Epoch 132/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.3155 - accuracy: 0.9431 - val_loss: 1.3138 - val_accuracy: 0.5561\n",
      "Epoch 133/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2908 - accuracy: 0.9482 - val_loss: 1.3159 - val_accuracy: 0.5549\n",
      "Epoch 134/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3048 - accuracy: 0.9383 - val_loss: 1.3164 - val_accuracy: 0.5549\n",
      "Epoch 135/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2954 - accuracy: 0.9439 - val_loss: 1.3192 - val_accuracy: 0.5549\n",
      "Epoch 136/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2953 - accuracy: 0.9479 - val_loss: 1.3213 - val_accuracy: 0.5536\n",
      "Epoch 137/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2819 - accuracy: 0.9521 - val_loss: 1.3230 - val_accuracy: 0.5524\n",
      "Epoch 138/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2742 - accuracy: 0.9524 - val_loss: 1.3244 - val_accuracy: 0.5524\n",
      "Epoch 139/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2700 - accuracy: 0.9609 - val_loss: 1.3264 - val_accuracy: 0.5524\n",
      "Epoch 140/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2787 - accuracy: 0.9496 - val_loss: 1.3277 - val_accuracy: 0.5536\n",
      "Epoch 141/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2732 - accuracy: 0.9562 - val_loss: 1.3297 - val_accuracy: 0.5536\n",
      "Epoch 142/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2748 - accuracy: 0.9526 - val_loss: 1.3317 - val_accuracy: 0.5512\n",
      "Epoch 143/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2620 - accuracy: 0.9615 - val_loss: 1.3342 - val_accuracy: 0.5524\n",
      "Epoch 144/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2528 - accuracy: 0.9581 - val_loss: 1.3362 - val_accuracy: 0.5512\n",
      "Epoch 145/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2455 - accuracy: 0.9607 - val_loss: 1.3372 - val_accuracy: 0.5512\n",
      "Epoch 146/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2494 - accuracy: 0.9582 - val_loss: 1.3393 - val_accuracy: 0.5512\n",
      "Epoch 147/200\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.2389 - accuracy: 0.9575 - val_loss: 1.3410 - val_accuracy: 0.5487\n",
      "Epoch 148/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.2417 - accuracy: 0.9619 - val_loss: 1.3426 - val_accuracy: 0.5475\n",
      "Epoch 149/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2374 - accuracy: 0.9612 - val_loss: 1.3444 - val_accuracy: 0.5475\n",
      "Epoch 150/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2361 - accuracy: 0.9614 - val_loss: 1.3463 - val_accuracy: 0.5487\n",
      "Epoch 151/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2292 - accuracy: 0.9614 - val_loss: 1.3497 - val_accuracy: 0.5487\n",
      "Epoch 152/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2396 - accuracy: 0.9591 - val_loss: 1.3510 - val_accuracy: 0.5487\n",
      "Epoch 153/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2211 - accuracy: 0.9691 - val_loss: 1.3532 - val_accuracy: 0.5487\n",
      "Epoch 154/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2337 - accuracy: 0.9599 - val_loss: 1.3549 - val_accuracy: 0.5487\n",
      "Epoch 155/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2265 - accuracy: 0.9612 - val_loss: 1.3570 - val_accuracy: 0.5487\n",
      "Epoch 156/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2260 - accuracy: 0.9672 - val_loss: 1.3586 - val_accuracy: 0.5487\n",
      "Epoch 157/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2113 - accuracy: 0.9689 - val_loss: 1.3600 - val_accuracy: 0.5487\n",
      "Epoch 158/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2216 - accuracy: 0.9661 - val_loss: 1.3610 - val_accuracy: 0.5487\n",
      "Epoch 159/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2199 - accuracy: 0.9631 - val_loss: 1.3645 - val_accuracy: 0.5475\n",
      "Epoch 160/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2109 - accuracy: 0.9714 - val_loss: 1.3670 - val_accuracy: 0.5475\n",
      "Epoch 161/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2038 - accuracy: 0.9688 - val_loss: 1.3673 - val_accuracy: 0.5487\n",
      "Epoch 162/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2019 - accuracy: 0.9676 - val_loss: 1.3697 - val_accuracy: 0.5487\n",
      "Epoch 163/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2023 - accuracy: 0.9681 - val_loss: 1.3713 - val_accuracy: 0.5487\n",
      "Epoch 164/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2010 - accuracy: 0.9710 - val_loss: 1.3741 - val_accuracy: 0.5487\n",
      "Epoch 165/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1877 - accuracy: 0.9736 - val_loss: 1.3765 - val_accuracy: 0.5487\n",
      "Epoch 166/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1897 - accuracy: 0.9736 - val_loss: 1.3777 - val_accuracy: 0.5487\n",
      "Epoch 167/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1975 - accuracy: 0.9686 - val_loss: 1.3799 - val_accuracy: 0.5487\n",
      "Epoch 168/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1966 - accuracy: 0.9704 - val_loss: 1.3811 - val_accuracy: 0.5487\n",
      "Epoch 169/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1824 - accuracy: 0.9778 - val_loss: 1.3840 - val_accuracy: 0.5499\n",
      "Epoch 170/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1905 - accuracy: 0.9728 - val_loss: 1.3854 - val_accuracy: 0.5512\n",
      "Epoch 171/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1912 - accuracy: 0.9705 - val_loss: 1.3873 - val_accuracy: 0.5499\n",
      "Epoch 172/200\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.1768 - accuracy: 0.9779 - val_loss: 1.3902 - val_accuracy: 0.5512\n",
      "Epoch 173/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1789 - accuracy: 0.9738 - val_loss: 1.3919 - val_accuracy: 0.5524\n",
      "Epoch 174/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1763 - accuracy: 0.9779 - val_loss: 1.3936 - val_accuracy: 0.5524\n",
      "Epoch 175/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1742 - accuracy: 0.9768 - val_loss: 1.3954 - val_accuracy: 0.5536\n",
      "Epoch 176/200\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1838 - accuracy: 0.9756 - val_loss: 1.3984 - val_accuracy: 0.5536\n",
      "Epoch 177/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1723 - accuracy: 0.9785 - val_loss: 1.3998 - val_accuracy: 0.5536\n",
      "Epoch 178/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1731 - accuracy: 0.9787 - val_loss: 1.4023 - val_accuracy: 0.5536\n",
      "Epoch 179/200\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.1715 - accuracy: 0.9763 - val_loss: 1.4031 - val_accuracy: 0.5536\n",
      "Epoch 180/200\n",
      "15/15 [==============================] - 0s 33ms/step - loss: 0.1649 - accuracy: 0.9783 - val_loss: 1.4046 - val_accuracy: 0.5524\n",
      "Epoch 181/200\n",
      "15/15 [==============================] - 1s 41ms/step - loss: 0.1696 - accuracy: 0.9778 - val_loss: 1.4077 - val_accuracy: 0.5536\n",
      "Epoch 182/200\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1701 - accuracy: 0.9749 - val_loss: 1.4102 - val_accuracy: 0.5524\n",
      "Epoch 183/200\n",
      "15/15 [==============================] - 1s 34ms/step - loss: 0.1655 - accuracy: 0.9774 - val_loss: 1.4111 - val_accuracy: 0.5536\n",
      "Epoch 184/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1549 - accuracy: 0.9791 - val_loss: 1.4139 - val_accuracy: 0.5549\n",
      "Epoch 185/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1620 - accuracy: 0.9805 - val_loss: 1.4165 - val_accuracy: 0.5549\n",
      "Epoch 186/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1592 - accuracy: 0.9798 - val_loss: 1.4172 - val_accuracy: 0.5549\n",
      "Epoch 187/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1496 - accuracy: 0.9829 - val_loss: 1.4184 - val_accuracy: 0.5549\n",
      "Epoch 188/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1538 - accuracy: 0.9833 - val_loss: 1.4196 - val_accuracy: 0.5536\n",
      "Epoch 189/200\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1549 - accuracy: 0.9798 - val_loss: 1.4222 - val_accuracy: 0.5524\n",
      "Epoch 190/200\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1472 - accuracy: 0.9826 - val_loss: 1.4248 - val_accuracy: 0.5524\n",
      "Epoch 191/200\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1442 - accuracy: 0.9820 - val_loss: 1.4265 - val_accuracy: 0.5524\n",
      "Epoch 192/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1412 - accuracy: 0.9872 - val_loss: 1.4288 - val_accuracy: 0.5536\n",
      "Epoch 193/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1427 - accuracy: 0.9863 - val_loss: 1.4306 - val_accuracy: 0.5524\n",
      "Epoch 194/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1362 - accuracy: 0.9869 - val_loss: 1.4326 - val_accuracy: 0.5524\n",
      "Epoch 195/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1389 - accuracy: 0.9854 - val_loss: 1.4341 - val_accuracy: 0.5536\n",
      "Epoch 196/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1366 - accuracy: 0.9866 - val_loss: 1.4361 - val_accuracy: 0.5549\n",
      "Epoch 197/200\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1329 - accuracy: 0.9885 - val_loss: 1.4384 - val_accuracy: 0.5536\n",
      "Epoch 198/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1321 - accuracy: 0.9864 - val_loss: 1.4394 - val_accuracy: 0.5536\n",
      "Epoch 199/200\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1353 - accuracy: 0.9869 - val_loss: 1.4416 - val_accuracy: 0.5524\n",
      "Epoch 200/200\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1312 - accuracy: 0.9873 - val_loss: 1.4433 - val_accuracy: 0.5524\n"
     ]
    }
   ],
   "source": [
    "# First NN\n",
    "histories = []\n",
    "\n",
    "for fold in training_folds:\n",
    "    X = validation_dict[fold]['X']\n",
    "    X_val = validation_dict[fold]['X_val']\n",
    "    y = validation_dict[fold]['y']\n",
    "    y_val = validation_dict[fold]['y_val']\n",
    "    X_reshaped = tf.reshape(X, [X.shape[0], X.shape[1] * X.shape[2]])\n",
    "    X_val_reshaped = tf.reshape(X_val, [X_val.shape[0], X_val.shape[1] * X_val.shape[2]])\n",
    "    \n",
    "    #model    \n",
    "    model = Sequential()\n",
    "    model.add(layers.InputLayer(input_shape = (X_reshaped.shape[1])))\n",
    "    model.add(layers.Dense(345, activation='relu'))\n",
    "    for l in range(2):\n",
    "        model.add(layers.Dense(154, activation='relu'))\n",
    "        if l%2 == 0:\n",
    "            model.add(layers.Dense(37, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    print(model.summary())\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum = 0.9)\n",
    "    model.compile(optimizer= optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping_callback = tensorflow.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "    # log dir for saving TensorBoard logs\n",
    "    #net_name = f\"first_nn_cv{fold}\"\n",
    "    #logdir = \"logs/fit/entire_data/\" + f\"first_nn_cv{fold}\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # callback to run TensorBoard\n",
    "    #tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq = 1)\n",
    "    \n",
    "    history = model.fit(X_reshaped,\n",
    "                        y,\n",
    "                        epochs = 200,\n",
    "                        batch_size = 200, \n",
    "                        validation_data = (X_val_reshaped, y_val),\n",
    "                        callbacks = [early_stopping_callback])\n",
    "    histories.append((fold, history, history.history, model))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f379804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cf4f0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-82fe04176949d424\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-82fe04176949d424\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit/entire_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77af8cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900812cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#provo togliendo mel e chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "132b57b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix_2(row):\n",
    "    if(np.array(row['spec_cent'][0]).shape[0]) == 345:\n",
    "        s = np.array([row[\"salience\"]] * np.array(row['spec_cent'][0]).shape[0])\n",
    "        matr = [np.array(row[\"spec_cent\"][0]),\n",
    "                np.array(row[\"spec_bw\"][0]), \n",
    "                np.array(row[\"rolloff\"][0]), \n",
    "                np.array(row[\"zcr\"][0]),\n",
    "                s]\n",
    "        return np.array(matr)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ab1a91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[(data[\"fold\"] == 1) | (data[\"fold\"] == 2) | (data[\"fold\"] == 3) | (data[\"fold\"] == 4) | (data[\"fold\"] == 6)]\n",
    "test = data[(data[\"fold\"] == 5) | (data[\"fold\"] == 7) | (data[\"fold\"] == 8) | (data[\"fold\"] == 9) | (data[\"fold\"] == 10)]\n",
    "\n",
    "X_train = train.reset_index()\n",
    "\n",
    "X_test = test.drop([\"class\", \"fold\"], axis = 1)\n",
    "y_test = test[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4dc0cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_m = np.ndarray(shape=(3792, 5, 345))\n",
    "j = 0\n",
    "to_drop = []\n",
    "for index, row in train.iterrows():\n",
    "    r = to_matrix_2(row)\n",
    "    if not np.any(np.isnan(r)):\n",
    "        X_train_m[j] = r\n",
    "        j = j + 1\n",
    "    else:\n",
    "        to_drop.append([index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54cff8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = np.setdiff1d(train.index, to_drop)\n",
    "X_train = data.loc[to_keep]\n",
    "X_train = X_train.reset_index()\n",
    "X_train_fold = X_train[\"fold\"]\n",
    "X_train_indices = X_train.index\n",
    "y_train = X_train[\"class\"]\n",
    "y_train_indices = y_train.index\n",
    "X_train = X_train_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "372c8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.ndarray(shape=(3534, 5, 345))\n",
    "j = 0\n",
    "for index, row in test.iterrows():\n",
    "    r = to_matrix_2(row)\n",
    "    if not np.any(np.isnan(r)):\n",
    "        X_test[j] = r\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e54bc340",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68e25935",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    scalers[i] = StandardScaler()\n",
    "    X_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
    "\n",
    "for i in range(X_test.shape[1]):\n",
    "    X_test[:, i, :] = scalers[i].transform(X_test[:, i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "588a43ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_folds = [4]\n",
    "validation_dict = {}\n",
    "for fold in training_folds:\n",
    "    #preparing validation folds\n",
    "    X_val = X_train[(X_train_fold == fold) | (X_train_fold == fold)]\n",
    "    X_val_indices = X_train_indices[(X_train_fold == fold) | (X_train_fold == fold)]\n",
    "    y_val = y_train[(X_train_fold == fold) | (X_train_fold == fold)]\n",
    "    y_val_indices = y_train_indices[(X_train_fold == fold) | (X_train_fold == fold)]\n",
    "    X = X_train[np.isin(X_train_indices,np.setdiff1d(X_train_indices, X_val_indices))]\n",
    "    y = y_train[np.isin(y_train_indices,np.setdiff1d(y_train_indices, y_val_indices))]\n",
    "    validation_dict[fold] = {'X' : X, 'y' : y, 'X_val': X_val, 'y_val': y_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "804d453e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 345)               4404270   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 154)               53284     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 37)                5735      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                380       \n",
      "=================================================================\n",
      "Total params: 4,463,669\n",
      "Trainable params: 4,463,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:52:16.002666: I tensorflow/python/profiler/internal/profiler_wrapper.cc:182] Profiling will start immediately because delay_ms was unset or zero.\n",
      "2021-08-25 14:52:16.008045: I tensorflow/core/profiler/lib/profiler_session.cc:133] Profiler session started.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x30fa53b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x30fa53b80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      " 3/30 [==>...........................] - ETA: 2s - loss: 2.5166 - accuracy: 0.1533 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-25 14:52:16.806063: I tensorflow/python/profiler/internal/profiler_wrapper.cc:182] Profiling will start immediately because delay_ms was unset or zero.\n",
      "2021-08-25 14:52:16.806099: I tensorflow/core/profiler/lib/profiler_session.cc:133] Profiler session started.\n",
      "2021-08-25 14:52:16.917866: I tensorflow/core/profiler/rpc/client/save_profile.cc:133] Creating directory: logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16\n",
      "2021-08-25 14:52:16.921991: I tensorflow/core/profiler/rpc/client/save_profile.cc:139] Dumped gzipped tool data for trace.json.gz to logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16/MBPdiElisabetta.Home.trace.json.gz\n",
      "2021-08-25 14:52:16.949088: I tensorflow/core/profiler/rpc/client/save_profile.cc:133] Creating directory: logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16\n",
      "2021-08-25 14:52:16.949321: I tensorflow/core/profiler/rpc/client/save_profile.cc:139] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16/MBPdiElisabetta.Home.memory_profile.json.gz\n",
      "2021-08-25 14:52:16.950411: I tensorflow/core/profiler/rpc/client/capture_profile.cc:235] Creating directory: logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16Dumped tool data for xplane.pb to logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16/MBPdiElisabetta.Home.xplane.pb\n",
      "Dumped tool data for overview_page.pb to logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16/MBPdiElisabetta.Home.overview_page.pb\n",
      "Dumped tool data for input_pipeline.pb to logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16/MBPdiElisabetta.Home.input_pipeline.pb\n",
      "Dumped tool data for tensorflow_stats.pb to logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16/MBPdiElisabetta.Home.tensorflow_stats.pb\n",
      "Dumped tool data for kernel_stats.pb to logs/fit/entire_data/first_nn_cv420210825-145215/train/plugins/profile/2021_08_25_14_52_16/MBPdiElisabetta.Home.kernel_stats.pb\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/30 [===========================>..] - ETA: 0s - loss: 2.4007 - accuracy: 0.1618WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x30f9fa0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x30f9fa0d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "30/30 [==============================] - 2s 37ms/step - loss: 2.3871 - accuracy: 0.1651 - val_loss: 2.0347 - val_accuracy: 0.2996\n",
      "Epoch 2/200\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 1.8608 - accuracy: 0.3492 - val_loss: 1.7968 - val_accuracy: 0.4094\n",
      "Epoch 3/200\n",
      "30/30 [==============================] - 1s 23ms/step - loss: 1.6130 - accuracy: 0.4568 - val_loss: 1.6802 - val_accuracy: 0.4476\n",
      "Epoch 4/200\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 1.4518 - accuracy: 0.5206 - val_loss: 1.6103 - val_accuracy: 0.4661\n",
      "Epoch 5/200\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 1.2969 - accuracy: 0.5929 - val_loss: 1.5545 - val_accuracy: 0.4797\n",
      "Epoch 6/200\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 1.1754 - accuracy: 0.6596 - val_loss: 1.5139 - val_accuracy: 0.4908\n",
      "Epoch 7/200\n",
      "30/30 [==============================] - 1s 26ms/step - loss: 1.1109 - accuracy: 0.6742 - val_loss: 1.4838 - val_accuracy: 0.5080\n",
      "Epoch 8/200\n",
      "30/30 [==============================] - 1s 27ms/step - loss: 1.0315 - accuracy: 0.7103 - val_loss: 1.4559 - val_accuracy: 0.5142\n",
      "Epoch 9/200\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.9426 - accuracy: 0.7462 - val_loss: 1.4349 - val_accuracy: 0.5277\n",
      "Epoch 10/200\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.8772 - accuracy: 0.7571 - val_loss: 1.4169 - val_accuracy: 0.5265\n",
      "Epoch 11/200\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.8231 - accuracy: 0.7814 - val_loss: 1.3986 - val_accuracy: 0.5314\n",
      "Epoch 12/200\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.7860 - accuracy: 0.7969 - val_loss: 1.3867 - val_accuracy: 0.5376\n",
      "Epoch 13/200\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.7279 - accuracy: 0.8184 - val_loss: 1.3788 - val_accuracy: 0.5388\n",
      "Epoch 14/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.7174 - accuracy: 0.8219 - val_loss: 1.3675 - val_accuracy: 0.5425\n",
      "Epoch 15/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.6717 - accuracy: 0.8265 - val_loss: 1.3650 - val_accuracy: 0.5487\n",
      "Epoch 16/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.6296 - accuracy: 0.8421 - val_loss: 1.3557 - val_accuracy: 0.5524\n",
      "Epoch 17/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.5953 - accuracy: 0.8529 - val_loss: 1.3550 - val_accuracy: 0.5561\n",
      "Epoch 18/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.5581 - accuracy: 0.8625 - val_loss: 1.3497 - val_accuracy: 0.5610\n",
      "Epoch 19/200\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.5306 - accuracy: 0.8700 - val_loss: 1.3471 - val_accuracy: 0.5598\n",
      "Epoch 20/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.5204 - accuracy: 0.8849 - val_loss: 1.3484 - val_accuracy: 0.5647\n",
      "Epoch 21/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4895 - accuracy: 0.8938 - val_loss: 1.3454 - val_accuracy: 0.5635\n",
      "Epoch 22/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.4745 - accuracy: 0.8902 - val_loss: 1.3489 - val_accuracy: 0.5635\n",
      "Epoch 23/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4619 - accuracy: 0.8903 - val_loss: 1.3476 - val_accuracy: 0.5672\n",
      "Epoch 24/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.4275 - accuracy: 0.9097 - val_loss: 1.3502 - val_accuracy: 0.5697\n",
      "Epoch 25/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.4087 - accuracy: 0.9199 - val_loss: 1.3496 - val_accuracy: 0.5684\n",
      "Epoch 26/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.4065 - accuracy: 0.9179 - val_loss: 1.3525 - val_accuracy: 0.5672\n",
      "Epoch 27/200\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.3827 - accuracy: 0.9211 - val_loss: 1.3557 - val_accuracy: 0.5660\n",
      "Epoch 28/200\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.3833 - accuracy: 0.9219 - val_loss: 1.3562 - val_accuracy: 0.5684\n",
      "Epoch 29/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3566 - accuracy: 0.9337 - val_loss: 1.3620 - val_accuracy: 0.5660\n",
      "Epoch 30/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3631 - accuracy: 0.9264 - val_loss: 1.3607 - val_accuracy: 0.5684\n",
      "Epoch 31/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.3288 - accuracy: 0.9402 - val_loss: 1.3652 - val_accuracy: 0.5660\n",
      "Epoch 32/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.3230 - accuracy: 0.9443 - val_loss: 1.3697 - val_accuracy: 0.5623\n",
      "Epoch 33/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.3241 - accuracy: 0.9447 - val_loss: 1.3726 - val_accuracy: 0.5623\n",
      "Epoch 34/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2908 - accuracy: 0.9544 - val_loss: 1.3725 - val_accuracy: 0.5623\n",
      "Epoch 35/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2950 - accuracy: 0.9538 - val_loss: 1.3781 - val_accuracy: 0.5598\n",
      "Epoch 36/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2864 - accuracy: 0.9565 - val_loss: 1.3810 - val_accuracy: 0.5610\n",
      "Epoch 37/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2729 - accuracy: 0.9594 - val_loss: 1.3844 - val_accuracy: 0.5598\n",
      "Epoch 38/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2614 - accuracy: 0.9576 - val_loss: 1.3901 - val_accuracy: 0.5610\n",
      "Epoch 39/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2539 - accuracy: 0.9671 - val_loss: 1.3912 - val_accuracy: 0.5623\n",
      "Epoch 40/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2427 - accuracy: 0.9644 - val_loss: 1.3949 - val_accuracy: 0.5635\n",
      "Epoch 41/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2318 - accuracy: 0.9727 - val_loss: 1.3996 - val_accuracy: 0.5660\n",
      "Epoch 42/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2242 - accuracy: 0.9690 - val_loss: 1.4039 - val_accuracy: 0.5623\n",
      "Epoch 43/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2332 - accuracy: 0.9677 - val_loss: 1.4043 - val_accuracy: 0.5623\n",
      "Epoch 44/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.2214 - accuracy: 0.9754 - val_loss: 1.4079 - val_accuracy: 0.5660\n",
      "Epoch 45/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2102 - accuracy: 0.9779 - val_loss: 1.4120 - val_accuracy: 0.5647\n",
      "Epoch 46/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2022 - accuracy: 0.9766 - val_loss: 1.4168 - val_accuracy: 0.5660\n",
      "Epoch 47/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1988 - accuracy: 0.9805 - val_loss: 1.4203 - val_accuracy: 0.5672\n",
      "Epoch 48/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1837 - accuracy: 0.9841 - val_loss: 1.4238 - val_accuracy: 0.5672\n",
      "Epoch 49/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1891 - accuracy: 0.9818 - val_loss: 1.4270 - val_accuracy: 0.5660\n",
      "Epoch 50/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1792 - accuracy: 0.9837 - val_loss: 1.4319 - val_accuracy: 0.5647\n",
      "Epoch 51/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1779 - accuracy: 0.9830 - val_loss: 1.4353 - val_accuracy: 0.5672\n",
      "Epoch 52/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1668 - accuracy: 0.9856 - val_loss: 1.4375 - val_accuracy: 0.5672\n",
      "Epoch 53/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1728 - accuracy: 0.9848 - val_loss: 1.4410 - val_accuracy: 0.5684\n",
      "Epoch 54/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1608 - accuracy: 0.9864 - val_loss: 1.4452 - val_accuracy: 0.5647\n",
      "Epoch 55/200\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1554 - accuracy: 0.9904 - val_loss: 1.4490 - val_accuracy: 0.5647\n",
      "Epoch 56/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1543 - accuracy: 0.9895 - val_loss: 1.4505 - val_accuracy: 0.5647\n",
      "Epoch 57/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1477 - accuracy: 0.9923 - val_loss: 1.4537 - val_accuracy: 0.5635\n",
      "Epoch 58/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1481 - accuracy: 0.9918 - val_loss: 1.4594 - val_accuracy: 0.5623\n",
      "Epoch 59/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.1394 - accuracy: 0.9925 - val_loss: 1.4614 - val_accuracy: 0.5610\n",
      "Epoch 60/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1425 - accuracy: 0.9911 - val_loss: 1.4663 - val_accuracy: 0.5635\n",
      "Epoch 61/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1319 - accuracy: 0.9927 - val_loss: 1.4666 - val_accuracy: 0.5623\n",
      "Epoch 62/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1341 - accuracy: 0.9916 - val_loss: 1.4714 - val_accuracy: 0.5635\n",
      "Epoch 63/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1256 - accuracy: 0.9924 - val_loss: 1.4749 - val_accuracy: 0.5635\n",
      "Epoch 64/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1226 - accuracy: 0.9922 - val_loss: 1.4792 - val_accuracy: 0.5623\n",
      "Epoch 65/200\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.1255 - accuracy: 0.9924 - val_loss: 1.4822 - val_accuracy: 0.5623\n",
      "Epoch 66/200\n",
      "30/30 [==============================] - 1s 22ms/step - loss: 0.1130 - accuracy: 0.9952 - val_loss: 1.4850 - val_accuracy: 0.5623\n",
      "Epoch 67/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1217 - accuracy: 0.9943 - val_loss: 1.4879 - val_accuracy: 0.5647\n",
      "Epoch 68/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1075 - accuracy: 0.9962 - val_loss: 1.4918 - val_accuracy: 0.5635\n",
      "Epoch 69/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1081 - accuracy: 0.9962 - val_loss: 1.4955 - val_accuracy: 0.5635\n",
      "Epoch 70/200\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1053 - accuracy: 0.9973 - val_loss: 1.4999 - val_accuracy: 0.5610\n",
      "Epoch 71/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.1026 - accuracy: 0.9975 - val_loss: 1.5011 - val_accuracy: 0.5623\n",
      "Epoch 72/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1067 - accuracy: 0.9961 - val_loss: 1.5043 - val_accuracy: 0.5635\n",
      "Epoch 73/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1011 - accuracy: 0.9960 - val_loss: 1.5061 - val_accuracy: 0.5623\n",
      "Epoch 74/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0996 - accuracy: 0.9945 - val_loss: 1.5101 - val_accuracy: 0.5623\n",
      "Epoch 75/200\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.0951 - accuracy: 0.9968 - val_loss: 1.5134 - val_accuracy: 0.5610\n",
      "Epoch 76/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0962 - accuracy: 0.9985 - val_loss: 1.5175 - val_accuracy: 0.5610\n",
      "Epoch 77/200\n",
      "30/30 [==============================] - 1s 21ms/step - loss: 0.0943 - accuracy: 0.9983 - val_loss: 1.5188 - val_accuracy: 0.5610\n",
      "Epoch 78/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0955 - accuracy: 0.9969 - val_loss: 1.5232 - val_accuracy: 0.5610\n",
      "Epoch 79/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0900 - accuracy: 0.9977 - val_loss: 1.5249 - val_accuracy: 0.5610\n",
      "Epoch 80/200\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.0865 - accuracy: 0.9973 - val_loss: 1.5283 - val_accuracy: 0.5610\n",
      "Epoch 81/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0867 - accuracy: 0.9992 - val_loss: 1.5310 - val_accuracy: 0.5610\n",
      "Epoch 82/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0834 - accuracy: 0.9992 - val_loss: 1.5353 - val_accuracy: 0.5598\n",
      "Epoch 83/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0871 - accuracy: 0.9984 - val_loss: 1.5362 - val_accuracy: 0.5610\n",
      "Epoch 84/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0813 - accuracy: 0.9985 - val_loss: 1.5408 - val_accuracy: 0.5598\n",
      "Epoch 85/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0778 - accuracy: 0.9994 - val_loss: 1.5419 - val_accuracy: 0.5610\n",
      "Epoch 86/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0784 - accuracy: 0.9989 - val_loss: 1.5447 - val_accuracy: 0.5610\n",
      "Epoch 87/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0726 - accuracy: 0.9995 - val_loss: 1.5476 - val_accuracy: 0.5623\n",
      "Epoch 88/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0729 - accuracy: 0.9994 - val_loss: 1.5503 - val_accuracy: 0.5623\n",
      "Epoch 89/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0724 - accuracy: 0.9992 - val_loss: 1.5534 - val_accuracy: 0.5623\n",
      "Epoch 90/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0699 - accuracy: 0.9996 - val_loss: 1.5551 - val_accuracy: 0.5635\n",
      "Epoch 91/200\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.0682 - accuracy: 0.99 - 0s 15ms/step - loss: 0.0683 - accuracy: 0.9993 - val_loss: 1.5588 - val_accuracy: 0.5623\n",
      "Epoch 92/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0707 - accuracy: 0.9994 - val_loss: 1.5601 - val_accuracy: 0.5623\n",
      "Epoch 93/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0670 - accuracy: 0.9994 - val_loss: 1.5634 - val_accuracy: 0.5623\n",
      "Epoch 94/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0670 - accuracy: 0.9995 - val_loss: 1.5657 - val_accuracy: 0.5635\n",
      "Epoch 95/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0638 - accuracy: 1.0000 - val_loss: 1.5666 - val_accuracy: 0.5660\n",
      "Epoch 96/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0668 - accuracy: 0.9987 - val_loss: 1.5724 - val_accuracy: 0.5623\n",
      "Epoch 97/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0623 - accuracy: 0.9998 - val_loss: 1.5725 - val_accuracy: 0.5647\n",
      "Epoch 98/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0606 - accuracy: 0.9995 - val_loss: 1.5749 - val_accuracy: 0.5647\n",
      "Epoch 99/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0606 - accuracy: 0.9999 - val_loss: 1.5776 - val_accuracy: 0.5635\n",
      "Epoch 100/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0566 - accuracy: 0.9995 - val_loss: 1.5799 - val_accuracy: 0.5647\n",
      "Epoch 101/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0591 - accuracy: 0.9998 - val_loss: 1.5834 - val_accuracy: 0.5635\n",
      "Epoch 102/200\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.0572 - accuracy: 0.9994 - val_loss: 1.5859 - val_accuracy: 0.5635\n",
      "Epoch 103/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0558 - accuracy: 0.9997 - val_loss: 1.5865 - val_accuracy: 0.5623\n",
      "Epoch 104/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0560 - accuracy: 0.9997 - val_loss: 1.5889 - val_accuracy: 0.5635\n",
      "Epoch 105/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0557 - accuracy: 0.9999 - val_loss: 1.5921 - val_accuracy: 0.5623\n",
      "Epoch 106/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0534 - accuracy: 0.9997 - val_loss: 1.5941 - val_accuracy: 0.5623\n",
      "Epoch 107/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0531 - accuracy: 0.9996 - val_loss: 1.5957 - val_accuracy: 0.5623\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0509 - accuracy: 0.9998 - val_loss: 1.5988 - val_accuracy: 0.5623\n",
      "Epoch 109/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0515 - accuracy: 0.9999 - val_loss: 1.6006 - val_accuracy: 0.5623\n",
      "Epoch 110/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0513 - accuracy: 0.9999 - val_loss: 1.6034 - val_accuracy: 0.5623\n",
      "Epoch 111/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0508 - accuracy: 0.9993 - val_loss: 1.6060 - val_accuracy: 0.5623\n",
      "Epoch 112/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0496 - accuracy: 0.9993 - val_loss: 1.6071 - val_accuracy: 0.5623\n",
      "Epoch 113/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0471 - accuracy: 0.9997 - val_loss: 1.6087 - val_accuracy: 0.5623\n",
      "Epoch 114/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0480 - accuracy: 0.9999 - val_loss: 1.6109 - val_accuracy: 0.5623\n",
      "Epoch 115/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0458 - accuracy: 0.9997 - val_loss: 1.6135 - val_accuracy: 0.5623\n",
      "Epoch 116/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0476 - accuracy: 0.9998 - val_loss: 1.6152 - val_accuracy: 0.5623\n",
      "Epoch 117/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0454 - accuracy: 0.9994 - val_loss: 1.6180 - val_accuracy: 0.5623\n",
      "Epoch 118/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0460 - accuracy: 0.9997 - val_loss: 1.6198 - val_accuracy: 0.5623\n",
      "Epoch 119/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0448 - accuracy: 0.9999 - val_loss: 1.6222 - val_accuracy: 0.5610\n",
      "Epoch 120/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0441 - accuracy: 0.9999 - val_loss: 1.6237 - val_accuracy: 0.5623\n",
      "Epoch 121/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0429 - accuracy: 0.9997 - val_loss: 1.6263 - val_accuracy: 0.5623\n",
      "Epoch 122/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0420 - accuracy: 0.9998 - val_loss: 1.6290 - val_accuracy: 0.5610\n",
      "Epoch 123/200\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.0417 - accuracy: 0.9998 - val_loss: 1.6307 - val_accuracy: 0.5610\n",
      "Epoch 124/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0409 - accuracy: 0.9994 - val_loss: 1.6326 - val_accuracy: 0.5610\n",
      "Epoch 125/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0409 - accuracy: 0.9998 - val_loss: 1.6357 - val_accuracy: 0.5610\n",
      "Epoch 126/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0417 - accuracy: 0.9996 - val_loss: 1.6361 - val_accuracy: 0.5610\n",
      "Epoch 127/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 1.6383 - val_accuracy: 0.5610\n",
      "Epoch 128/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0387 - accuracy: 0.9996 - val_loss: 1.6393 - val_accuracy: 0.5610\n",
      "Epoch 129/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0396 - accuracy: 0.9997 - val_loss: 1.6427 - val_accuracy: 0.5598\n",
      "Epoch 130/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0390 - accuracy: 0.9987 - val_loss: 1.6442 - val_accuracy: 0.5598\n",
      "Epoch 131/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0394 - accuracy: 0.9995 - val_loss: 1.6459 - val_accuracy: 0.5598\n",
      "Epoch 132/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0370 - accuracy: 1.0000 - val_loss: 1.6475 - val_accuracy: 0.5610\n",
      "Epoch 133/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 1.6496 - val_accuracy: 0.5610\n",
      "Epoch 134/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.6511 - val_accuracy: 0.5610\n",
      "Epoch 135/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0356 - accuracy: 1.0000 - val_loss: 1.6529 - val_accuracy: 0.5610\n",
      "Epoch 136/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 1.6554 - val_accuracy: 0.5610\n",
      "Epoch 137/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 1.6568 - val_accuracy: 0.5610\n",
      "Epoch 138/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 1.6580 - val_accuracy: 0.5610\n",
      "Epoch 139/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.6607 - val_accuracy: 0.5610\n",
      "Epoch 140/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 1.6618 - val_accuracy: 0.5610\n",
      "Epoch 141/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.6641 - val_accuracy: 0.5623\n",
      "Epoch 142/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 1.6644 - val_accuracy: 0.5610\n",
      "Epoch 143/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0318 - accuracy: 1.0000 - val_loss: 1.6670 - val_accuracy: 0.5610\n",
      "Epoch 144/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.6685 - val_accuracy: 0.5623\n",
      "Epoch 145/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0317 - accuracy: 1.0000 - val_loss: 1.6701 - val_accuracy: 0.5623\n",
      "Epoch 146/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 1.6722 - val_accuracy: 0.5623\n",
      "Epoch 147/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 1.6729 - val_accuracy: 0.5623\n",
      "Epoch 148/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.6740 - val_accuracy: 0.5635\n",
      "Epoch 149/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0302 - accuracy: 1.0000 - val_loss: 1.6771 - val_accuracy: 0.5623\n",
      "Epoch 150/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0298 - accuracy: 1.0000 - val_loss: 1.6778 - val_accuracy: 0.5623\n",
      "Epoch 151/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 1.6791 - val_accuracy: 0.5647\n",
      "Epoch 152/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.6809 - val_accuracy: 0.5647\n",
      "Epoch 153/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0294 - accuracy: 1.0000 - val_loss: 1.6829 - val_accuracy: 0.5647\n",
      "Epoch 154/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.6846 - val_accuracy: 0.5635\n",
      "Epoch 155/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0299 - accuracy: 1.0000 - val_loss: 1.6860 - val_accuracy: 0.5647\n",
      "Epoch 156/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 1.6878 - val_accuracy: 0.5635\n",
      "Epoch 157/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.6886 - val_accuracy: 0.5647\n",
      "Epoch 158/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 1.6900 - val_accuracy: 0.5647\n",
      "Epoch 159/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.6923 - val_accuracy: 0.5647\n",
      "Epoch 160/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 1.6936 - val_accuracy: 0.5647\n",
      "Epoch 161/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 1.6944 - val_accuracy: 0.5660\n",
      "Epoch 162/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 1.6965 - val_accuracy: 0.5647\n",
      "Epoch 163/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0280 - accuracy: 1.0000 - val_loss: 1.6970 - val_accuracy: 0.5660\n",
      "Epoch 164/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.6996 - val_accuracy: 0.5660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.7008 - val_accuracy: 0.5647\n",
      "Epoch 166/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0251 - accuracy: 1.0000 - val_loss: 1.7019 - val_accuracy: 0.5647\n",
      "Epoch 167/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0260 - accuracy: 1.0000 - val_loss: 1.7033 - val_accuracy: 0.5647\n",
      "Epoch 168/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.7058 - val_accuracy: 0.5660\n",
      "Epoch 169/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0259 - accuracy: 1.0000 - val_loss: 1.7062 - val_accuracy: 0.5660\n",
      "Epoch 170/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 1.7089 - val_accuracy: 0.5660\n",
      "Epoch 171/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 1.7093 - val_accuracy: 0.5647\n",
      "Epoch 172/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0241 - accuracy: 1.0000 - val_loss: 1.7111 - val_accuracy: 0.5660\n",
      "Epoch 173/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.7119 - val_accuracy: 0.5672\n",
      "Epoch 174/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 1.7139 - val_accuracy: 0.5660\n",
      "Epoch 175/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 1.7153 - val_accuracy: 0.5660\n",
      "Epoch 176/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.7168 - val_accuracy: 0.5672\n",
      "Epoch 177/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.7183 - val_accuracy: 0.5684\n",
      "Epoch 178/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 1.7193 - val_accuracy: 0.5684\n",
      "Epoch 179/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.7207 - val_accuracy: 0.5672\n",
      "Epoch 180/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 1.7214 - val_accuracy: 0.5672\n",
      "Epoch 181/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.7238 - val_accuracy: 0.5672\n",
      "Epoch 182/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.7252 - val_accuracy: 0.5672\n",
      "Epoch 183/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 1.7264 - val_accuracy: 0.5672\n",
      "Epoch 184/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 1.7272 - val_accuracy: 0.5672\n",
      "Epoch 185/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.7288 - val_accuracy: 0.5672\n",
      "Epoch 186/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 1.7298 - val_accuracy: 0.5660\n",
      "Epoch 187/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.7317 - val_accuracy: 0.5660\n",
      "Epoch 188/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.7331 - val_accuracy: 0.5660\n",
      "Epoch 189/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.7345 - val_accuracy: 0.5660\n",
      "Epoch 190/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.7362 - val_accuracy: 0.5672\n",
      "Epoch 191/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.7365 - val_accuracy: 0.5660\n",
      "Epoch 192/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.7382 - val_accuracy: 0.5660\n",
      "Epoch 193/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.7402 - val_accuracy: 0.5660\n",
      "Epoch 194/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.7401 - val_accuracy: 0.5660\n",
      "Epoch 195/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.7420 - val_accuracy: 0.5660\n",
      "Epoch 196/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.7438 - val_accuracy: 0.5660\n",
      "Epoch 197/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 1.7451 - val_accuracy: 0.5660\n",
      "Epoch 198/200\n",
      "30/30 [==============================] - 0s 14ms/step - loss: 0.0203 - accuracy: 1.0000 - val_loss: 1.7458 - val_accuracy: 0.5660\n",
      "Epoch 199/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.7470 - val_accuracy: 0.5660\n",
      "Epoch 200/200\n",
      "30/30 [==============================] - 0s 15ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.7479 - val_accuracy: 0.5672\n"
     ]
    }
   ],
   "source": [
    "# First NN\n",
    "histories = []\n",
    "\n",
    "for fold in training_folds:\n",
    "    X = validation_dict[fold]['X']\n",
    "    X_val = validation_dict[fold]['X_val']\n",
    "    y = validation_dict[fold]['y']\n",
    "    y_val = validation_dict[fold]['y_val']\n",
    "    X_reshaped = tf.reshape(X, [X.shape[0], X.shape[1] * X.shape[2]])\n",
    "    X_val_reshaped = tf.reshape(X_val, [X_val.shape[0], X_val.shape[1] * X_val.shape[2]])\n",
    "    \n",
    "    #model    \n",
    "    model = Sequential()\n",
    "    model.add(layers.InputLayer(input_shape = (X_reshaped.shape[1])))\n",
    "    model.add(layers.Dense(345, activation='relu'))\n",
    "    for l in range(1):\n",
    "        model.add(layers.Dense(154, activation='relu'))\n",
    "        if l%2 == 0:\n",
    "            model.add(layers.Dense(37, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    print(model.summary())\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.0001, momentum = 0.9)\n",
    "    model.compile(optimizer= optimizer,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping_callback = tensorflow.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "    # log dir for saving TensorBoard logs\n",
    "    net_name = f\"first_nn_cv{fold}\"\n",
    "    logdir = \"logs/fit/entire_data/\" + f\"first_nn_cv{fold}\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # callback to run TensorBoard\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq = 1)\n",
    "    \n",
    "    history = model.fit(X_reshaped,\n",
    "                        y,\n",
    "                        epochs = 200,\n",
    "                        batch_size = 100, \n",
    "                        validation_data = (X_val_reshaped, y_val),\n",
    "                        callbacks = [early_stopping_callback, tensorboard_callback])\n",
    "    histories.append((fold, history, history.history, model))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90758154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non uso il flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98049eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2981, 5, 345)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " validation_dict[fold]['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef2b43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7bd4dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_515 (Conv1D)          (None, 5, 37)             25567     \n",
      "_________________________________________________________________\n",
      "conv1d_516 (Conv1D)          (None, 5, 37)             2775      \n",
      "_________________________________________________________________\n",
      "conv1d_517 (Conv1D)          (None, 5, 37)             2775      \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 185)               0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 100)               18600     \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 50,727\n",
      "Trainable params: 50,727\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x287124280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x287124280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "17/30 [================>.............] - ETA: 0s - loss: 2.0989 - accuracy: 0.2294WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2871244c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2871244c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 1.9893 - accuracy: 0.2683 - val_loss: 1.8074 - val_accuracy: 0.3872\n",
      "Epoch 2/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.4836 - accuracy: 0.4490 - val_loss: 1.9949 - val_accuracy: 0.4229\n",
      "Epoch 3/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.3682 - accuracy: 0.4961 - val_loss: 1.9966 - val_accuracy: 0.4550\n",
      "Epoch 4/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.2128 - accuracy: 0.5753 - val_loss: 2.2627 - val_accuracy: 0.4057\n",
      "Epoch 5/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1879 - accuracy: 0.5784 - val_loss: 2.2459 - val_accuracy: 0.4525\n",
      "Epoch 6/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 1.1032 - accuracy: 0.6088 - val_loss: 2.3496 - val_accuracy: 0.4365\n",
      "Epoch 7/150\n",
      "30/30 [==============================] - 0s 5ms/step - loss: 1.0550 - accuracy: 0.6236 - val_loss: 2.4527 - val_accuracy: 0.4414\n",
      "Epoch 8/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9555 - accuracy: 0.6712 - val_loss: 2.4967 - val_accuracy: 0.4562\n",
      "Epoch 9/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.9504 - accuracy: 0.6730 - val_loss: 2.3741 - val_accuracy: 0.4501\n",
      "Epoch 10/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8702 - accuracy: 0.6945 - val_loss: 2.4561 - val_accuracy: 0.4538\n",
      "Epoch 11/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8590 - accuracy: 0.6995 - val_loss: 2.5612 - val_accuracy: 0.4599\n",
      "Epoch 12/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.8206 - accuracy: 0.7209 - val_loss: 2.6173 - val_accuracy: 0.4673\n",
      "Epoch 13/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7345 - accuracy: 0.7468 - val_loss: 2.7103 - val_accuracy: 0.4464\n",
      "Epoch 14/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7840 - accuracy: 0.7241 - val_loss: 2.7092 - val_accuracy: 0.4784\n",
      "Epoch 15/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.7546 - val_loss: 2.8091 - val_accuracy: 0.4809\n",
      "Epoch 16/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6938 - accuracy: 0.7598 - val_loss: 3.0198 - val_accuracy: 0.4279\n",
      "Epoch 17/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6616 - accuracy: 0.7715 - val_loss: 3.1219 - val_accuracy: 0.4538\n",
      "Epoch 18/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.7858 - val_loss: 3.0109 - val_accuracy: 0.4414\n",
      "Epoch 19/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.7920 - val_loss: 2.9680 - val_accuracy: 0.4562\n",
      "Epoch 20/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5868 - accuracy: 0.7853 - val_loss: 3.1474 - val_accuracy: 0.4698\n",
      "Epoch 21/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5649 - accuracy: 0.8046 - val_loss: 3.2720 - val_accuracy: 0.4057\n",
      "Epoch 22/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.8155 - val_loss: 3.1494 - val_accuracy: 0.4698\n",
      "Epoch 23/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.5034 - accuracy: 0.8257 - val_loss: 3.3851 - val_accuracy: 0.4414\n",
      "Epoch 24/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.8327 - val_loss: 3.3233 - val_accuracy: 0.4550\n",
      "Epoch 25/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.8425 - val_loss: 3.6402 - val_accuracy: 0.5006\n",
      "Epoch 26/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.8443 - val_loss: 3.4580 - val_accuracy: 0.4612\n",
      "Epoch 27/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8553 - val_loss: 3.5399 - val_accuracy: 0.4895\n",
      "Epoch 28/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4080 - accuracy: 0.8645 - val_loss: 3.9840 - val_accuracy: 0.4538\n",
      "Epoch 29/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4082 - accuracy: 0.8668 - val_loss: 4.0417 - val_accuracy: 0.4242\n",
      "Epoch 30/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8685 - val_loss: 4.1106 - val_accuracy: 0.4624\n",
      "Epoch 31/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.4039 - accuracy: 0.8573 - val_loss: 3.8549 - val_accuracy: 0.4735\n",
      "Epoch 32/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8884 - val_loss: 4.0121 - val_accuracy: 0.4562\n",
      "Epoch 33/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.8909 - val_loss: 3.9364 - val_accuracy: 0.4821\n",
      "Epoch 34/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3364 - accuracy: 0.8846 - val_loss: 4.5260 - val_accuracy: 0.4735\n",
      "Epoch 35/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3475 - accuracy: 0.8801 - val_loss: 4.2154 - val_accuracy: 0.4698\n",
      "Epoch 36/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3281 - accuracy: 0.8933 - val_loss: 4.1123 - val_accuracy: 0.4908\n",
      "Epoch 37/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 0.9004 - val_loss: 4.3191 - val_accuracy: 0.4661\n",
      "Epoch 38/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2857 - accuracy: 0.9000 - val_loss: 4.6153 - val_accuracy: 0.4834\n",
      "Epoch 39/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.9141 - val_loss: 4.5550 - val_accuracy: 0.4908\n",
      "Epoch 40/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8857 - val_loss: 4.3298 - val_accuracy: 0.4525\n",
      "Epoch 41/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8705 - val_loss: 4.3965 - val_accuracy: 0.5055\n",
      "Epoch 42/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.9165 - val_loss: 4.7773 - val_accuracy: 0.4599\n",
      "Epoch 43/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.9216 - val_loss: 4.6805 - val_accuracy: 0.4908\n",
      "Epoch 44/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.9213 - val_loss: 4.7254 - val_accuracy: 0.4969\n",
      "Epoch 45/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2211 - accuracy: 0.9281 - val_loss: 4.9624 - val_accuracy: 0.4858\n",
      "Epoch 46/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2233 - accuracy: 0.9277 - val_loss: 5.0212 - val_accuracy: 0.4599\n",
      "Epoch 47/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2202 - accuracy: 0.9268 - val_loss: 5.0528 - val_accuracy: 0.4846\n",
      "Epoch 48/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1994 - accuracy: 0.9370 - val_loss: 5.0232 - val_accuracy: 0.4673\n",
      "Epoch 49/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1796 - accuracy: 0.9443 - val_loss: 5.1360 - val_accuracy: 0.4920\n",
      "Epoch 50/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2064 - accuracy: 0.9362 - val_loss: 5.3259 - val_accuracy: 0.4920\n",
      "Epoch 51/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1648 - accuracy: 0.9495 - val_loss: 5.3307 - val_accuracy: 0.4723\n",
      "Epoch 52/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1615 - accuracy: 0.9529 - val_loss: 5.6774 - val_accuracy: 0.4747\n",
      "Epoch 53/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.9553 - val_loss: 5.6691 - val_accuracy: 0.4821\n",
      "Epoch 54/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9506 - val_loss: 5.6595 - val_accuracy: 0.4908\n",
      "Epoch 55/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2128 - accuracy: 0.9265 - val_loss: 5.6936 - val_accuracy: 0.4599\n",
      "Epoch 56/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.9317 - val_loss: 5.7567 - val_accuracy: 0.4624\n",
      "Epoch 57/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1703 - accuracy: 0.9430 - val_loss: 5.7974 - val_accuracy: 0.4920\n",
      "Epoch 58/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1356 - accuracy: 0.9567 - val_loss: 5.9412 - val_accuracy: 0.5031\n",
      "Epoch 59/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1371 - accuracy: 0.9550 - val_loss: 5.8065 - val_accuracy: 0.4809\n",
      "Epoch 60/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1220 - accuracy: 0.9631 - val_loss: 5.8459 - val_accuracy: 0.4451\n",
      "Epoch 61/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.9466 - val_loss: 5.8932 - val_accuracy: 0.4772\n",
      "Epoch 62/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1540 - accuracy: 0.9524 - val_loss: 6.1227 - val_accuracy: 0.4784\n",
      "Epoch 63/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9625 - val_loss: 6.2895 - val_accuracy: 0.4809\n",
      "Epoch 64/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1379 - accuracy: 0.9524 - val_loss: 6.0282 - val_accuracy: 0.4698\n",
      "Epoch 65/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.9641 - val_loss: 6.2408 - val_accuracy: 0.4686\n",
      "Epoch 66/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1419 - accuracy: 0.9606 - val_loss: 6.3400 - val_accuracy: 0.4858\n",
      "Epoch 67/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1456 - accuracy: 0.9527 - val_loss: 6.5609 - val_accuracy: 0.4772\n",
      "Epoch 68/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1132 - accuracy: 0.9650 - val_loss: 6.4885 - val_accuracy: 0.5006\n",
      "Epoch 69/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9692 - val_loss: 6.8279 - val_accuracy: 0.4747\n",
      "Epoch 70/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9624 - val_loss: 6.5925 - val_accuracy: 0.4686\n",
      "Epoch 71/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9644 - val_loss: 6.6962 - val_accuracy: 0.4858\n",
      "Epoch 72/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.9663 - val_loss: 6.4820 - val_accuracy: 0.4686\n",
      "Epoch 73/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9654 - val_loss: 6.8663 - val_accuracy: 0.4636\n",
      "Epoch 74/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9703 - val_loss: 7.0066 - val_accuracy: 0.4649\n",
      "Epoch 75/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9782 - val_loss: 6.9152 - val_accuracy: 0.4760\n",
      "Epoch 76/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9803 - val_loss: 7.0842 - val_accuracy: 0.4883\n",
      "Epoch 77/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9746 - val_loss: 7.0706 - val_accuracy: 0.4501\n",
      "Epoch 78/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0976 - accuracy: 0.9633 - val_loss: 7.5316 - val_accuracy: 0.4686\n",
      "Epoch 79/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1155 - accuracy: 0.9603 - val_loss: 7.1413 - val_accuracy: 0.4784\n",
      "Epoch 80/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0692 - accuracy: 0.9838 - val_loss: 7.1549 - val_accuracy: 0.4821\n",
      "Epoch 81/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0684 - accuracy: 0.9785 - val_loss: 7.1736 - val_accuracy: 0.4834\n",
      "Epoch 82/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0738 - accuracy: 0.9803 - val_loss: 7.4313 - val_accuracy: 0.4945\n",
      "Epoch 83/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1118 - accuracy: 0.9629 - val_loss: 7.4903 - val_accuracy: 0.4698\n",
      "Epoch 84/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1040 - accuracy: 0.9662 - val_loss: 7.6752 - val_accuracy: 0.4723\n",
      "Epoch 85/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9776 - val_loss: 7.4490 - val_accuracy: 0.4920\n",
      "Epoch 86/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0522 - accuracy: 0.9855 - val_loss: 7.8343 - val_accuracy: 0.4871\n",
      "Epoch 87/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0420 - accuracy: 0.9905 - val_loss: 8.0501 - val_accuracy: 0.4772\n",
      "Epoch 88/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9848 - val_loss: 8.1191 - val_accuracy: 0.4661\n",
      "Epoch 89/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 7.7254 - val_accuracy: 0.5142\n",
      "Epoch 90/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9724 - val_loss: 7.6905 - val_accuracy: 0.4747\n",
      "Epoch 91/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9764 - val_loss: 7.8716 - val_accuracy: 0.4871\n",
      "Epoch 92/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0661 - accuracy: 0.9787 - val_loss: 7.9419 - val_accuracy: 0.4797\n",
      "Epoch 93/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0551 - accuracy: 0.9811 - val_loss: 8.1743 - val_accuracy: 0.4686\n",
      "Epoch 94/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9811 - val_loss: 8.1485 - val_accuracy: 0.4920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1103 - accuracy: 0.9678 - val_loss: 7.5577 - val_accuracy: 0.4834\n",
      "Epoch 96/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1436 - accuracy: 0.9504 - val_loss: 7.9591 - val_accuracy: 0.4821\n",
      "Epoch 97/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.9600 - val_loss: 7.9737 - val_accuracy: 0.4291\n",
      "Epoch 98/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1547 - accuracy: 0.9478 - val_loss: 7.5155 - val_accuracy: 0.5031\n",
      "Epoch 99/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1308 - accuracy: 0.9543 - val_loss: 7.7179 - val_accuracy: 0.4723\n",
      "Epoch 100/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9672 - val_loss: 7.5228 - val_accuracy: 0.4846\n",
      "Epoch 101/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0804 - accuracy: 0.9731 - val_loss: 7.5195 - val_accuracy: 0.4821\n",
      "Epoch 102/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0615 - accuracy: 0.9830 - val_loss: 7.5603 - val_accuracy: 0.4661\n",
      "Epoch 103/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9903 - val_loss: 7.7182 - val_accuracy: 0.4908\n",
      "Epoch 104/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0275 - accuracy: 0.9948 - val_loss: 7.8228 - val_accuracy: 0.4908\n",
      "Epoch 105/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9966 - val_loss: 7.7808 - val_accuracy: 0.4698\n",
      "Epoch 106/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9978 - val_loss: 8.0496 - val_accuracy: 0.4895\n",
      "Epoch 107/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0245 - accuracy: 0.9937 - val_loss: 8.0308 - val_accuracy: 0.4735\n",
      "Epoch 108/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9952 - val_loss: 8.1495 - val_accuracy: 0.4846\n",
      "Epoch 109/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9944 - val_loss: 8.3851 - val_accuracy: 0.4698\n",
      "Epoch 110/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0397 - accuracy: 0.9861 - val_loss: 8.2528 - val_accuracy: 0.4686\n",
      "Epoch 111/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0378 - accuracy: 0.9886 - val_loss: 8.4103 - val_accuracy: 0.4772\n",
      "Epoch 112/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 8.2642 - val_accuracy: 0.4883\n",
      "Epoch 113/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9841 - val_loss: 8.4513 - val_accuracy: 0.4883\n",
      "Epoch 114/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9939 - val_loss: 8.5543 - val_accuracy: 0.5043\n",
      "Epoch 115/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9947 - val_loss: 8.6120 - val_accuracy: 0.4747\n",
      "Epoch 116/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9951 - val_loss: 8.6099 - val_accuracy: 0.4809\n",
      "Epoch 117/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9896 - val_loss: 8.8507 - val_accuracy: 0.4612\n",
      "Epoch 118/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9963 - val_loss: 8.7198 - val_accuracy: 0.4895\n",
      "Epoch 119/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 8.9012 - val_accuracy: 0.4908\n",
      "Epoch 120/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0189 - accuracy: 0.9956 - val_loss: 8.7801 - val_accuracy: 0.4723\n",
      "Epoch 121/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0214 - accuracy: 0.9952 - val_loss: 8.7600 - val_accuracy: 0.4846\n",
      "Epoch 122/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 8.8886 - val_accuracy: 0.5006\n",
      "Epoch 123/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9948 - val_loss: 8.8126 - val_accuracy: 0.4895\n",
      "Epoch 124/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9963 - val_loss: 9.2388 - val_accuracy: 0.4649\n",
      "Epoch 125/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0096 - accuracy: 0.9993 - val_loss: 9.1694 - val_accuracy: 0.4575\n",
      "Epoch 126/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9974 - val_loss: 9.3703 - val_accuracy: 0.4920\n",
      "Epoch 127/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9981 - val_loss: 9.2942 - val_accuracy: 0.4673\n",
      "Epoch 128/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9913 - val_loss: 8.8997 - val_accuracy: 0.4451\n",
      "Epoch 129/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0445 - accuracy: 0.9837 - val_loss: 9.7891 - val_accuracy: 0.4340\n",
      "Epoch 130/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9657 - val_loss: 8.7005 - val_accuracy: 0.4328\n",
      "Epoch 131/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1497 - accuracy: 0.9478 - val_loss: 8.2891 - val_accuracy: 0.4957\n",
      "Epoch 132/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2132 - accuracy: 0.9240 - val_loss: 8.3514 - val_accuracy: 0.4057\n",
      "Epoch 133/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.2194 - accuracy: 0.9337 - val_loss: 7.5543 - val_accuracy: 0.4661\n",
      "Epoch 134/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.1022 - accuracy: 0.9602 - val_loss: 7.9526 - val_accuracy: 0.4550\n",
      "Epoch 135/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0437 - accuracy: 0.9880 - val_loss: 8.3962 - val_accuracy: 0.4698\n",
      "Epoch 136/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 0.9933 - val_loss: 8.7261 - val_accuracy: 0.4957\n",
      "Epoch 137/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0176 - accuracy: 0.9957 - val_loss: 8.5354 - val_accuracy: 0.4920\n",
      "Epoch 138/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9984 - val_loss: 8.7041 - val_accuracy: 0.4895\n",
      "Epoch 139/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9990 - val_loss: 8.7994 - val_accuracy: 0.4932\n",
      "Epoch 140/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0071 - accuracy: 0.9997 - val_loss: 8.8638 - val_accuracy: 0.4895\n",
      "Epoch 141/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 8.9661 - val_accuracy: 0.4932\n",
      "Epoch 142/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 9.0199 - val_accuracy: 0.4858\n",
      "Epoch 143/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 9.1011 - val_accuracy: 0.4945\n",
      "Epoch 144/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0040 - accuracy: 0.9999 - val_loss: 9.1833 - val_accuracy: 0.4846\n",
      "Epoch 145/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 9.2265 - val_accuracy: 0.4957\n",
      "Epoch 146/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 9.3819 - val_accuracy: 0.4895\n",
      "Epoch 147/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 9.3738 - val_accuracy: 0.4945\n",
      "Epoch 148/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 9.4254 - val_accuracy: 0.4945\n",
      "Epoch 149/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 9.4689 - val_accuracy: 0.4895\n",
      "Epoch 150/150\n",
      "30/30 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 9.5178 - val_accuracy: 0.4809\n"
     ]
    }
   ],
   "source": [
    "#cnn\n",
    "histories = []\n",
    "\n",
    "for fold in training_folds:\n",
    "    X = validation_dict[fold]['X']\n",
    "    X_val = validation_dict[fold]['X_val']\n",
    "    y = validation_dict[fold]['y']\n",
    "    y_val = validation_dict[fold]['y_val']\n",
    "\n",
    "    #model    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=37, kernel_size=2,  padding='same', activation='relu', input_shape=(X.shape[1], X.shape[2])))\n",
    "    #model.add(Conv1D(filters=345, kernel_size=2,   padding='same', activation='relu'))\n",
    "    #model.add(layers.Dropout(0.2))\n",
    "    #model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    for l in range(1):\n",
    "        model.add(Conv1D(filters=37, kernel_size=2,  padding='same', activation='relu'))\n",
    "        model.add(Conv1D(filters=37, kernel_size=2,   padding='same', activation='relu'))\n",
    "        #model.add(layers.Dropout(0.1))\n",
    "        #model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    print(model.summary())\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.001, momentum = 0.9)\n",
    "    model.compile(optimizer= 'adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    early_stopping_callback = tensorflow.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "    # log dir for saving TensorBoard logs\n",
    "    #net_name = f\"first_nn_cv{fold}\"\n",
    "    #logdir = \"logs/fit/entire_data/\" + f\"first_nn_cv{fold}\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # callback to run TensorBoard\n",
    "    #tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq = 1)\n",
    "    \n",
    "    history = model.fit(X,\n",
    "                        y,\n",
    "                        epochs = 150,\n",
    "                        batch_size = 100, \n",
    "                        validation_data = (X_val, y_val),\n",
    "                        callbacks = [])\n",
    "    histories.append((fold, history, history.history, model))\n",
    "    break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7a68f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tf_m1': conda)",
   "language": "python",
   "name": "python3810jvsc74a57bd0d8423a7c5f0add4bbe1caca8a5de1580bbb6fd1666ce65ae15fa23061d14fbed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
